% Этот шаблон документа разработан в 2014 году
% Данилом Фёдоровых (danil@fedorovykh.ru) 
% для использования в курсе 
% <<Документы и презентации в \LaTeX>>, записанном НИУ ВШЭ
% для Coursera.org: http://coursera.org/course/latex .
% Исходная версия шаблона --- 
% https://www.writelatex.com/coursera/latex/2

\documentclass[a4paper,12pt]{article}

%%% Работа с русским языком
\usepackage{cmap}					% поиск в PDF
\usepackage{mathtext} 				% русские буквы в формулах
\usepackage[T2A]{fontenc}			% кодировка
\usepackage[utf8]{inputenc}			% кодировка исходного текста
\usepackage[english,russian]{babel}	% локализация и переносы

\usepackage{hyperref}

%%% Дополнительная работа с математикой
\usepackage{amsfonts,amssymb,amsthm,mathtools} % AMS
\usepackage{amsmath}
\usepackage{icomma} % "Умная" запятая: $0,2$ --- число, $0, 2$ --- перечисление

%% Номера формул
%\mathtoolsset{showonlyrefs=true} % Показывать номера только у тех формул, на которые есть \eqref{} в тексте.

%% Шрифты
\usepackage{euscript}	 % Шрифт Евклид
\usepackage{mathrsfs} % Красивый матшрифт

%% Управление цветами документа
\usepackage{xcolor}

%% Свои команды
\DeclareMathOperator{\sgn}{\mathop{sgn}}
\DeclareMathOperator{\tr}{\mathop{tr}}
\DeclareMathOperator{\img}{\mathop{Img}}
\DeclareMathOperator{\spn}{\mathop{span}}
\DeclareMathOperator{\rank}{\mathop{rank}}
\DeclareMathOperator{\ind}{\mathop{ind}}
\DeclareMathOperator{\pr}{\mathop{pr}}
\DeclareMathOperator{\ort}{\mathop{ort}}

\newtheorem*{definition}{Опр}

\newtheorem*{lemma}{Лемма}
\newtheorem{theorem}{Теорема}[section]

\newtheorem{propos}{Предл}[section]

\newtheorem*{prob}{Задача}
\newtheorem*{remark}{Замечание}
\newtheorem*{corollary}{Следствие}

\newenvironment{soln}{\noindent\textit{Решение.}}{\hfill$\square$}

%% Перенос знаков в формулах (по Львовскому)
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}
{\hbox{$\mathsurround=0pt #1$}}{}}

%%% Работа с картинками
\usepackage{graphicx}  % Для вставки рисунков
\graphicspath{{images/}{images2/}{img/}}  % папки с картинками
\setlength\fboxsep{3pt} % Отступ рамки \fbox{} от рисунка
\setlength\fboxrule{1pt} % Толщина линий рамки \fbox{}
\usepackage{wrapfig} % Обтекание рисунков и таблиц текстом

%%% Работа с таблицами
\usepackage{array,tabularx,tabulary,booktabs} % Дополнительная работа с таблицами
\usepackage{longtable}  % Длинные таблицы
\usepackage{multirow} % Слияние строк в таблице

%%% Геометрия страницы
\usepackage[right=15mm, left=20mm, top=15mm, bottom=20mm, nohead]{geometry}

\usepackage{indentfirst}

\newcounter{propcnt}
%\def\propcnt{\arabic{subsection}}


%%% Заголовок
\author{Anonymous}
\title{Алгебраическое}
\date{\today}

\begin{document} % конец преамбулы, начало документа

\maketitle

Заметки по линейной алгебре в литературной обработке. Их вряд ли стоит читать во время еды, но если читатель сочтет слог не слишком сухим, автор будет считать свою цель достигнутой. 

Пара слов о структуре. Сюжет основан на курсе линейной алгебры от МФТИ и следует ему практически без отклонений. Со своей стороны автор постарался внедрить в структуру повествования ряд идей, обозначенных В.Н. Дятловым на семинарах по математическому анализу в НГУ. Коротко их можно сформулировать так: изучение математики опирается как на теоретические знания, так и на практические навыки решения задач и доказательства теорем. Очень часто между этими гранями зияет пустота. Поэтому имеет смысл уделить внимание технологической части, где будут сформулированы  общие эвристики и способы применения теорем к решению практических вопросов.

\section{Дополнение}
\colorbox{yellow}{Некоторое интересное дополнение, для анализа линейных систем.}

\colorbox{yellow}{Ещё хочется добавить напоминание, как пользоваться алгоритмом решения СЛАУ}

О решении систем линейных уравнений. 
\begin{enumerate}
	\item Если левая часть образует базис некоторого пространства (подпространства), в котором лежит и вектор правой части. То система имеет одно решение в силу единственности разложения по базису.
	\item Если вектор правой части не попадает в пространство, образованное векторами системы, то решений нет.
	\item Если левая часть содержит избыток векторов (т.е. они линейно зависимы) и вектор правой части лежит в образованном ими пространстве, то решений будет бесконечно много (некоторое решение + нулевое пространство)
\end{enumerate}

\section{Понятие линейного пространства}

\subsection{Замена базиса}
\begin{theorem}
	Пусть в линейном пространстве $L$ заданы базисы $e$ и $e'$, $e' = eS$. $S$ -- матрица перехода от $e$ к $e'$, состоящая из координатных столбцов $e_j'$ в базисе $e$, $\det S \ne 0$, т.к. столбцы линейно независимы.
	
	Тогда если $x = e \xi = e' \xi'$, то $e = e' S^{-1}$ и $\xi' = S^{-1} \xi$.
\end{theorem}
\begin{proof}
	Матрица преобразования $S$ невырожденная, т.е. у неё есть обратная $\det S \ne 0$ $\Rightarrow$ $ \exists S^{-1}$. Домножим обе части выражения $e' = eS$ на матрицу $S^{-1}$ справа и проведем преобразования: $e' S^{-1} = e S S^{-1}$ $\Rightarrow$ $e' S^{-1} = e$.
	
	Подставим в тождество $x = e \xi = e' \xi'$ выражение для базиса $e' = eS$ и переставим скобки по ассоциативности: $(eS) \xi' = e(S\xi')$. Из единственности разложения по базису $e$  можно приравнять соответствующие координатные столбцы $e \xi = e (S \xi')$ $\Rightarrow$ $\xi = S \xi'$. Домножив на $S^{-1}$ слева, получим искомое выражение $S^{-1} \xi = \xi'$.
\end{proof}


\section{Линейные подпространства линейных пространств}

\subsection{Определение линейного подпространства}

\begin{definition}
	Непустое подмножество $L'$ линейного пространства $L$ называется линейным подпространством, если 
	\begin{enumerate}
		\item $\forall x, y \in L'$  $(x + y) \in L'$, т.е. сумма любых элементов множества $L'$ не выходит за его границы.
		\item $\forall x \in L'$, $\forall \alpha$ $(\alpha x ) \in L'$, результат умножения элементов $L'$ на скаляр также не выходит за границу $L'$.
	\end{enumerate}
\end{definition}

Интересно заметить, что прочие аксиомы линейного пространства проверять не нужно, потому что они уже выполняются для объемлющего множества $L$. Т.е. линейное подпространство является ЛП. 

Тривиальные примеры: нулевое подпространство, всё ЛП $L$. Ещё пример -- множество решений СЛАУ $Ax = 0$ как подмножество пространства столбцов.

\begin{propos}
	Пусть $L_n$ -- ЛП размерности $n$, тогда любую линейно независимую упорядоченную систему векторов из $m < n$ элементов можно дополнить до базиса в $L_n$.
\end{propos}

\begin{proof}	
	$m < n$ $\Rightarrow$ данная система не является базисом. Т.е. найдется элемент, невыразимый с помощью ЛК данной системы: $\exists x \in L_n$, $x \not \in L_n$. Добавим его, получится $(m+1)$ ЛНЗ векторов. Операцию поиска и добавления вектора повторяем, пока их число не достигнет $n$. Это и будет базис.
\end{proof}

\begin{definition}
	Пусть дано множество $P$ векторов из ЛП $L$, а $L'$ -- множество всевозможных конечный линейных комбинаций векторов из $P$. Построенное таким образом множество $L'$ называется линейной оболочкой множества $P$, обозначим его как $\spn(P)$.
\end{definition}

\begin{propos}
	$\spn(P)$ -- подпространство в $L$.
\end{propos}

\begin{propos}
	$L' = \spn(P)$, $P$ -- конечное множество из $m$ векторов. Тогда $\dim L' \le m$.  
\end{propos}

\begin{propos}
	$L'$ -- линейное подпространство ЛП $L_n$. Тогда $\dim L' \le n$. Равенство достигается т. и т.т., когда $L' = L_n$.
\end{propos}

\begin{propos}
	Пусть в ЛП $L_n$ задан базис. Тогда координатные столбцы векторов из подпространства $L_k'$ $(k < n)$ -- решения однородной СЛАУ с матрицей ранга $(n-k)$.
\end{propos}

\subsubsection{Технологии}

Теоремы и утверждения, сформулированные в теоретическом разделе, создают ощущение, что линейные пространства имеют определенную внутреннюю структуру, которая описывается с помощью системы подпространств. Попробуем немного поработать с ней собственными руками. 

\begin{prob}
	Пусть $\Phi$ -- фундаментальная матрица (составлена из фундаментальной системы решений) СЛАУ  $Ax = 0$. Тогда система $\Phi^T y = 0$ задает линейную оболочку строк матрицы $A$, т.е. все конечные линейные комбинации строк матрицы $A$ удовлетворяют этой системе.
\end{prob}
\begin{proof}
	Выберем из строк матрицы $A \in M_{m \times n}$ $\rank A = r$ линейно независимый поднабор $A'$, при этом линейная оболочка не изменится, $\spn(A) = \spn(A')$, $A' \in M_{r \times n}$, $\rank M = r$.
	
	Для системы $Ax = 0$ фундаментальная матрица $\Phi$ является матрицей вида $M_{n \times (n-r)}$.
	
	Т.к. фундаментальная матрица содержит решения системы, $A' \Phi = 0$. Транспонировав матричное произведение, получим $\Phi^T A'^T = 0$. Результат следует интерпретировать так: столбцы матрицы $A'^T$ являются решениями системы $\Phi^T y = 0$.
	
	Матрица $A'^T$ является фундаментальной для $\Phi^T y = 0$, т.к. согласуется по размерам,а её столбцы линейно независимы по построению. Поэтому система $\Phi^T y = 0$ действительно определяет линейную оболочку столбцов $A'^T$ или строк матрицы $A'$, а значит и матрицы $A$.
\end{proof}



\subsection{Операции над подпространствами}

\begin{definition}
	Пусть $L'$ и $L''$ --  линейные подпространства ЛП $L$. Пересечением $L' \cap L''$ называется их пересечение как множеств. Т.е. берутся векторы лежащие в каждом из подпространств. 
\end{definition}

Пересечение не будет пусто, всегда остается нулевой вектор!

\begin{definition}
	Суммой $L' + L''$ линейный подпространств ЛП $L$ называется линейная оболочка $\spn(L' \cup L'')$. Т.е. $\forall x \in (L' + L'')$ существует представление $x = x' + x''$, где $x' \in L'$, а $x'' \in L''$.
\end{definition}


\subsection{Формула Грассмана}
\begin{theorem}[формула Грассмана]
	Пусть $L'$ и $L''$ -- линейные подпространства ЛП $L$ конечной размерности. Тогда
	\[
		\dim(L' + L'') = \dim L' + \dim L'' - \dim (L' \cap L'')
	\]
\end{theorem}

\subsection{Прямая сумма подпространств}

\begin{definition}
	Если линейные подпространства $L'$ и $L''$ ЛП $L$ имеют нулевое (не пустое!) пересечение $L' \cap L'' = 0$, то их сумма $(L' + L'')$ будет называться прямой. Обозначение: $L' \oplus L''$.
\end{definition}

Базис такой системы можно построить простым объединением базисов $L'$ и $L''$.

\begin{propos}
	$\forall x \in (L' \oplus L'')$ существуют единственное разложение вида $x' \in L'$ и $x'' \in L''$, такие что $x = x' + x''$. Будем называть $x'$ проекцией вектора $x$ на $L'$ вдоль $L''$, а $x''$ -- проекцией вектора $x$ на $L''$ вдоль $L'$.
\end{propos}

\subsubsection{Технологии}

\begin{prob}
	Найти какое-нибудь прямое дополнение в $\mathbb{R}^4$ к линейной оболочке векторов $(1,2,1,2)^T$, $(1,3,2,4)^T$.
\end{prob}
\begin{soln}
	Мы знаем, что у любого подпространства в конечномерном пространстве есть прямое дополнение.
	Кроме того, базис подпространства можно дополнить до базиса объемлющего пространства. Т.е. для решения задачи достаточно найти базис исходной линейной оболочки и вычислить его дополнение. Линейная оболочка, построенная на дополняющих векторах, образует прямое дополнение.
			
	Пусть $U$ ($\dim U = k$) -- какое-то подпространство в $V$ ($\dim V = n$), выберем базис $\{e_1, \ldots, e_k \}$ в $U$ и дополним его до $\{e_1, \ldots, e_k, e_{k+1}, \ldots e_n\}$ до базиса в $V$. Определим $W = \langle e_{k+1}, \ldots, e_n \rangle$ и рассмотрим $V = U + W$. Пересечение $U$ и $W$ нулевое, т.к. векторы $\{e_i\}$ линейно независимы, поэтому сумма будет прямой $V = U \oplus W$.
	 
	Теперь мы можем провести необходимые вычисления. Для этого выпишем заданные вектор-столбцы и дополним их стандартным базисом в $\mathbb{R}^4$. Полученную матрицу приведем элементарными преобразованиями строк (преобразования столбцов тоже подойдут) к ступенчатому виду.
	\[
		\begin{pmatrix}
			1 & 1 & 1 & 0 & 0 & 0 \\
			2 & 3 & 0 & 1 & 0 & 0 \\
			1 & 2 & 0 & 0 & 1 & 0 \\
			2 & 4 & 0 & 0 & 0 & 1
  		\end{pmatrix}
		\to 
		\begin{pmatrix}
			1 & 1 & 1 & 0 & 0 & 0 \\
			0 & 1 &-2 & 1 & 0 & 0 \\
			0 & 0 & 1 &-1 & 1 & 0 \\
			0 & 0 & 0 & 0 &-2 & 1
		\end{pmatrix}	
	\]
	Базисные столбцы имеют номера 1,2,3,5. Получается, что линейную оболочку $U$ можно дополнить векторами $(1,0,0,0)^T$ и $(0,0,1,0)^T$.
\end{soln}

\section{Линейные отображения линейных пространств}

\subsection{Определение линейных отображений линейных пространств}

\begin{definition}
	Пусть $L$ и $\tilde{L}$ -- два ЛП одного типа (оба комплексные или оба вещественные). Отображение $\varphi: L \to \tilde{L}$ -- это правило, по которому каждому элементу $x \in L$ сопоставлен единственный $y \in \tilde{L}$. 
\end{definition}

В соотношении $y = \varphi(x)$ будем назвать $y$ образом $x$, а $x$ -- прообразом $y$.

\begin{definition}
	Отображение $\varphi: L \to \tilde{L}$ называется линейным, если $\forall x,y \in L$, $\forall \alpha \in \mathbb{R}$ (или $\mathbb{C}$)
	\begin{enumerate}
		\item $\varphi(x+y) = \varphi(x) + \varphi(y)$;
		\item $\varphi(\alpha x) = \alpha \varphi(x)$.
	\end{enumerate}
\end{definition}

\begin{definition}
	Если $L$ совпадает с $\tilde{L}$, то линейное отображение $\varphi : L \to \tilde{L}$ называется линейным преобразованием.
\end{definition}

\subsubsection{Технологии}

Линейные отображения сами по себе обладают очень хорошими свойствами. Если доказать принадлежность интересующего отображения $\varphi$ к классу линейных, то появится возможность применить весь накопленный арсенал инструментов. Также для достаточно простых отображений полезно получить некоторое интуитивное понимание.

\begin{prob}
	Пусть $x$ -- произвольный вектор, $a$, $n$ -- фиксированные векторы геометрического трехмерного пространства $V$ такие, что $(a,n) \ne 0$. Необходимо проверить линейность преобразования $\varphi$, заданного формулой
	\[
		\varphi(x) = x - \dfrac{(x,n)}{(a,n)} a
	\]
	и выяснить его геометрический смысл.
\end{prob}

 \begin{prob}
 	Пусть $V = U \oplus W$. Докажите, что преобразование $\varphi: V \to V$, сопоставляющее произвольному вектору его проекцию на $U$ вдоль $W$, $\varphi(v) = u$, является линейным. 
 \end{prob}


\subsection{Свойства линейных отображений и преобразований}
\begin{propos}
	При линейном отображении $\varphi: L_n \to \tilde{L}_m$ линейное подпространство $L' \subseteq L_n$ переходит в линейное подпространство $\varphi(L') \subseteq \tilde{L}_m$, причем $\dim \varphi(L') \le \dim L'$.
\end{propos}

\begin{proof} $\Rightarrow$ 
	
	Нулевое подпространство $L' = 0$ перейдет в нулевое $\varphi(L') = 0$.	Пусть $L' \ne 0$ с базисом $e = (e_1, \ldots, e_k)$, тогда $\forall x \in L'$ можно взять его разложение $x = \xi_1 e_1 + \ldots + \xi_k e_k$ и подействовать линейным преобразованием: 
	\[
		\varphi(x) = \xi_1 \varphi(e_1) + \ldots + \xi_k \varphi(e_k), 		
	\]
	т.е. всякий вектор $y = \varphi(x) \in \varphi(L')$ является линейной комбинацией образов базисных векторов $(\varphi(e_1), \ldots, \varphi(e_k))$. $\varphi(L')$ -- это множество образов всех векторов из $L'$.
	
	$\Leftarrow$
	
	Любая линейная комбинация вида $\xi_1 \varphi(e_1) + \ldots + \xi_k \varphi(e_k)$ -- образ некоторого вектора из $L'$, а $\varphi(L') = \spn(\varphi(e_1), \ldots, \varphi(e_k))$, т.е. линейное подпространство. А т.к. число образов не превосходит исходного числа векторов и конечно, то $\dim(L') \le k$.	
\end{proof}

\begin{definition}
	$\varphi(L_n)$ -- множество значений $\varphi$, обозначение $\img \varphi$.
\end{definition}

Чтобы не возникло путаницы, напомним, что преобразование $\varphi$ определено на всём пространстве, но результат его действия не обязательно равен исходному пространству.

\begin{definition}
	Рангом преобразования называется значение $\rank \varphi = \dim(\img \varphi)$.	
\end{definition}

\begin{definition}
Если $\rank \varphi = m$, то $\varphi(L_n) = \tilde{L}_m$ и любой вектор $\tilde{x} \in \tilde{L}_m$ -- есть образ некоторого $x \in L_n$. Такое отображение будем называть сюръекцией (или наложением).
\end{definition}

\begin{definition}
	Множество векторов из $L_n$, переходящих в $\tilde{0} \in \tilde{L}_m$ при отображении $\varphi$ называется ядром $\varphi$. Обозначение $\ker \varphi$.
\end{definition}

\begin{propos}
	$\ker \varphi$  -- линейное подпространство в $L_n$.
\end{propos}

\begin{definition}
	$\varphi: L_n \to L_m$ называется инъекцией (или вложением), если разные векторы из $L_n$ имеют различные образы.
\end{definition}

\begin{propos}
	$\varphi$ -- инъекция $ \Leftrightarrow$ $\ker \varphi = 0$.
\end{propos}

Координаты невозможны без базиса! Пусть $e = (e_1, \ldots, e_n)$ -- базис в $L_n$, $f = (f_1, \ldots, f_m)$ -- базис в $\tilde{L}_m$, $\varphi: L_n \to L_m$. Если $x = e\xi$, то $\varphi(x) = \varphi(e)\xi$. Разложим $\varphi(e_i)$ по базису $f$:
\[
	\varphi(e_i) = \sum_{p = 1}^{m} \alpha_{ip} f_p, \quad i = 1, \ldots, n
\]
Пусть $\varphi(x) = f \eta$, тогда $\eta = A \xi$, где 

\[
A = \begin{pmatrix}
		a_{11} & \ldots & a_{1n} \\
		\ldots & \ldots & \ldots \\
		a_{m1} & \ldots & a_{mm}
	\end{pmatrix}
\] 
-- матрица линейного отображения в паре базисов $e$ и $f$. Столбцы матрицы $A$ -- координатные столбцы векторов $\varphi(e_1), \ldots, \varphi(e_n)$ в базисе $f$ (слева направо).

\begin{propos}
	Ранг отображения $\rank \varphi$ равен рангу матрицы $\rank A$.
\end{propos}
\begin{proof}
	Пусть $j_1 \ldots, j_r$ -- номера базисных столбцов матрицы $A$. Тогда $\varphi(e_{j_1}, \ldots, e_{j_r})$ -- линейно независимы, а $\varphi(e_i)$ -- их линейная комбинация ($i = 1, \ldots, n$). Получается, что образ $\varphi(x)$ выражается только через образы базисных векторов, соответствующих базисным столбцам $\varphi(e_{j_1}, \ldots, e_{j_r})$. Эти векторы -- базис в $\img \varphi$. Получается, что $r = \dim(\img \varphi) = \rank \varphi$, но $r = \rank A$.
\end{proof}

\begin{propos}
	Ранг отображения $\rank \varphi$ является его инвариантом, т.е. не зависит от выбора пары базисов в $L_n$ и $\tilde{L}_m$.
\end{propos}

\subsubsection{Технологии}
Задачи на построение линейного преобразования, обладающего заданными свойствами. 

\begin{prob}
	Пусть $V$ -- трехмерное ориентированное геометрической пространство. Нужно найти матрицу линейного преобразования $\varphi_v : V \to V$, заданного формулой $\varphi_v(x) = [v, x]$ в правом ортонормированном базисе. Примечание: операция $[\_,\_]$ -- векторное произведение.
\end{prob}
\begin{soln}
	Существование такой матрицы следует из линейности векторного произведения. 
	
	Рассмотрим, как преобразование действует на базисные вектора $(e_1, e_2, e_3)$, записанные с помощью их координатного представления.
	\[
		\varphi_v(e_1) = [v, e_1] = 		
		\begin{vmatrix}
			e_1 & e_2 & e_3 \\
			v_1 & v_2 & v_3 \\
			1 & 0 & 0
		\end{vmatrix} = v_3 e_2 - v_2 e_3
	\]
	
	\[
	\varphi_v(e_2) = [v, e_2] = 		
		\begin{vmatrix}
			e_1 & e_2 & e_3 \\
			v_1 & v_2 & v_3 \\
			0 & 1 & 0
		\end{vmatrix} = v_2 e_1 - v_1 e_3
	\]
	\[
	\varphi_v(e_3) = [v, e_3] = 		
		\begin{vmatrix}
			e_1 & e_2 & e_3 \\
			v_1 & v_2 & v_3 \\
			0 & 0 & 1
		\end{vmatrix} = v_1 e_2 - v_2 e_1
	\]
Теперь, пользуясь линейностью можно собрать матрицу преобразования целиком (матрица собирается по столбцам, как линейная комбинация векторов базиса!):
\[
	A = \begin{pmatrix}
		0 & -v_3 & v_2 \\
		v_3 & 0 & -v_1 \\
		-v_2 & v_1 & 0
	\end{pmatrix}
\]
Такая матрица является вырожденной, например, вектор $v = (v_1, v_2, v_3)$ лежит в ядре.
\end{soln}

\begin{prob}
	Найти матрицу оператора $\varphi = \frac{d}{dx}$ на линейной оболочке $\langle \sin x, \cos x \rangle$ в базисе $\{ \sin x, \cos x\}$.
\end{prob}
\begin{soln}
	Линейная оболочка имеет вид 
	\[
		\langle \sin x, \cos x \rangle = \{ \lambda \sin x + \mu \cos x \; \vert \; \lambda, \mu \in \mathbb{R}\} 
	\]
	Зная, как действует оператор дифференцирования на отдельные функции, можно записать преобразование для координат базисных векторов: 
	\[
		[\cos x, 0] = [ \sin x, \cos x] A [1, 0]^T 
	\]
	\[
		[0, -\sin x] = [ \sin x, \cos x] A [0, 1]^T
	\]
	\[
		A = \begin{pmatrix}
			0 & -1 \\
			1 & 0 
		\end{pmatrix}
	\]
\end{soln}

\begin{prob}
	Привести пример линейного оператора $\varphi$, для которого $\ker \varphi = \img \varphi$ (ядро и образ совпадают).
\end{prob}
\begin{soln}
	Пусть $\varphi : V \to V$ -- ЛП, попробуем разобраться, как выглядит его необычное свойство.  Если взять некоторый вектор $u \ne 0$, то он будет находиться и в ядре и в образе $\varphi$, то есть $u \in \ker \varphi \cap \img \varphi$. Этот вектор с одной стороны является образом какого-то другого вектора $u = \varphi(v), \; v \in V$, с другой стороны под действием преобразования переходит в ноль $\varphi(u) = 0$. 
	
	Можно сказать, что $v \in V: \varphi(v) \ne 0$, $\varphi^2(v) = 0$. Примером такого оператора является оператор дифференцирования над пространством многочленов степени не выше 1 $\varphi = \frac{d}{dx}$ $\mathbb{R}[x]_1 \to \mathbb{R}[x]_1$. Базис такого пространства состоит из многочленов $\{1, x\}$. Константы переходят в ноль, т.е. $\ker \varphi = \langle 1\rangle$, кроме того под действием $\varphi$ все многочлены теряют степень, значит $\img \varphi = \langle 1\rangle$. 
	
	В матричном виде оператор $\varphi$ в базисе $\{1, x\}$ имеет вид
	\[
		A = \begin{pmatrix}
			0 & 1 \\
			0 & 0 
		\end{pmatrix}
	\]
	ядро будет являться пространством решений системы $A x = 0$ $\ker \varphi = \langle (1 0)^T\rangle$, образ -- это линейная оболочка столбцов $A$, $\img \varphi = \langle (1 0)^T\rangle$. Ядро и образ совпадают!
	
	В каких пространствах возможно определить такой оператор? Мы знаем, что $\dim \ker \varphi + \dim \img \varphi = \dim V$. В нашем случае $\dim \ker \varphi = \dim \img \varphi$ $\Rightarrow$ $\dim V = 2n$ -- пространство должно иметь четную размерность.
\end{soln}

\subsection{Замена базиса}

\begin{definition}
	Отображение $\varphi: L_n \to \tilde{L}_m$ называется взаимно однозначным, если $\forall \tilde{x} \in \tilde{L}_m$ является образом единственного $x \in L_n$.
\end{definition}

\begin{propos}[Критерий взаимного однозначного отображения]
	Отображение $\varphi: L_n \to \tilde{L}_m$ взаимно однозначно $\Leftrightarrow$ $n = m = r$, где $r = \rank \varphi$.
\end{propos}

\begin{definition}
	Взаимно однозначное линейное отображение $\varphi: L_n \to \tilde{L}_m$ называется изоморфизмом $L_n$ на $\tilde{L}_m$. Если между пространствами существует изоморфизм, то они изоморфны.
\end{definition}

\begin{theorem}[об изоморфизме]
	Линейные пространства $L_n$ и $\tilde{L}_m$ изоморфны $\Leftrightarrow$ $\dim L_n = \dim \tilde{L}_m$.
\end{theorem}

Теорему можно интерпретировать так, что линейное пространство данной размерности одно (с точностью до изоморфизма). \\


Рассмотрим, как изменится матрица линейного отображения при замене базисов. На старте у нас есть следующие объекты: 
\begin{itemize}
	\item линейное отображение $\varphi: L_n \to \tilde{L}_m$;
	\item $e$ -- базис в $L_n$ и $f$ -- базис в $\tilde{L}_m$;
	\item $e' = eS$, $f' = fF$ -- преобразования базисов (соответствующие им матрицы невырожденные!);
	\item $A$ -- матрица $\varphi$ в паре $e,f$;
	\item $A'$ -- матрица $\varphi$ в паре $e', f'$.
\end{itemize}
Вопрос: как найти матрицу $A'$, зная исходную матрицу $A$, а также $S$ и $F$? 

\begin{theorem}
	\[	
		A' = F^{-1}AS
	\]
\end{theorem}
\begin{proof}
	Рассуждение можно проводить двумя способами: относительно координатных столбцов или преобразования базисных векторов. 
	
	При замене базиса координатные столбцы изменяются следующим образом
	\[ \xi = S \xi', \quad \eta = F \eta'\]	
	
	Действие оператора в этих базисах можно представить вот так
	\[ \eta = A \xi, \quad \eta' = A'\xi' \]
	где $\xi$ и $\xi'$ -- координатные столбцы $x \in L_n$ в базисах $e$ и $e'$, а $\eta$ и $\eta'$ -- координатные столбы $\phi(x) \in \tilde{L}_m$ в базисах $f$ и $f'$.
	
	Выполнив подстановку базисных замен для $\eta$ и $\xi$ в формулу оператора $\eta = A \xi$, получим
	\[
		F \eta' = AS\xi' \quad  \Rightarrow \quad \eta' = F^{-1}AS \xi'
	\]
	С другой стороны $\eta' = A' \xi'$, поэтому из единственности разложения по базису следует равенство матриц
	\[
		A' = F^{-1} A S
	\]
	Примечание: нам не нужно беспокоиться об обратимости $F^{-1}$, т.к. это матрица перехода, преобразующая базис в базис, а она всегда обратима.
\end{proof}


Замена базиса является не просто каким-то вычислительным упражнением. Не все базисы одинаково полезны, среди них есть те, что позволяют существенно упростить внешний вид преобразования.

\begin{theorem}
	Для любого линейного отображения $\varphi: L_n \to \tilde{L}_m$, $\rank \varphi = r$, существуют базисы $e$ в $L_n$ и $f$ в $\tilde{L}_m$, такие что матрица $\varphi$ имеет блочный вид
	\[
		A = \begin{pmatrix}
			E_r & 0 \\
			0 & 0 
		\end{pmatrix}
	\]	
	Замечание: для линейных преобразований теорема в общем случае не верна.
\end{theorem}

\subsubsection{Технологии}
Теорема о нахождении матрицы оператора в новом базисе достаточно проста в плане применения, потому что она сразу предлагает алгоритм для вычисления преобразований. В первую очередь здесь важно не терять бдительность и следить за тем, в каком направлении действуют матрицы. 

\begin{prob}
	Линейный оператор в некотором базисе $\{e_1, e_2, e_3\}$ имеет матрицу
	\[
		A = \begin{pmatrix}
			3 & 2 & 2 \\
			-2 & 1 &0 \\
			3 & 3 & -2
		\end{pmatrix}
	\]
	Найти его матрицу в базисе 
	\begin{align*}
		e_1' &= e_1 + 2e_2 + e_3, \\
		e_2' &= -7e_1 + 4e_2 - 2e_3, \\
		e_3' &= 3e_1 - e_2 + e_3		
	\end{align*}	
\end{prob}

\begin{soln}
	Выпишем матрицу $S$ преобразования базиса $e' = eS$
	\[
		S = \begin{pmatrix}
			1 & -7 &  3 \\
			2 &  4 & -1 \\
			1 & -2 &  1
		\end{pmatrix}
	\]
	Т.к. оператор является преобразованием пространства, теорему о замене базиса оператора можно записать вот так
	\[
		A' = S^{-1} A S
	\]
	
	Чтобы получить ответ нужно просто вычислить $S^{-1}$, а потом перемножить матрицы.
	
	\[
		S^{-1} = \begin{pmatrix}
			-2 & -1 &  5 \\
			3 &  2 & -7 \\
			8 & 5 &  -18
		\end{pmatrix}
	\]
	
	\[
		A' = S^{-1} A S = 
		\begin{pmatrix}
			17 & -9 &  9 \\
			-22 & 20 & -15 \\
			-54 & 44 &  -35
		\end{pmatrix}
	\]
	
\end{soln}

\subsection{Операции над линейными отображениями}
\begin{definition}
	Пусть $\varphi: L \to \tilde{L}$, $\psi: L \to \tilde{L}$ -- линейные отображения. Каждому $x \in L$ сопоставим элемент $\varphi(x) + \psi(x)$ из $\tilde{L}$. Такое отображение $(\varphi + \psi)$ назовём суммой $\varphi$ и $\psi$.
\end{definition}

\begin{definition}
	Пусть $\varphi: L \to \tilde{L}$ -- линейное отображение, $\alpha$ -- число. Каждому $x \in L$ сопоставим $\alpha \varphi(x)$ из $\tilde{L}$. Такое отображение $\alpha \varphi$ назовём произведением $\varphi$ на число $\alpha$.
\end{definition}

Если задуматься о свойствах линейных отображений, то можно понять, что оба отображения окажутся линейными. Этот факт оказывается довольно удобным для практических вычислений. 

\begin{enumerate}
	\item Если в $L$ и $\tilde{L}$ выбраны базисы $e$ и $f$, то матрица $\varphi + \psi$ в этой паре базисов есть $A + B$, где $A + B$ -- матрицы $\varphi$ и $\psi$ в выбранных базисах.
	\item Если $A$ -- матрица $\varphi$ в базисах $e$, $f$, то матрица $\alpha \varphi$ будет иметь вид $\alpha A$.
\end{enumerate}

Фактически оказывается, что множество линейных отображений $L_n \to \tilde{L}_m$ является линейным пространством, изоморфным линейному пространству матриц $M_{m \times n}$.

\begin{definition}
	Результат последовательного выполнения линейных отображений $\varphi: L \to \tilde{L}$ и $\psi: \tilde{L}\to \bar{L}$ называется произведением (или композицией) отображений $\varphi$ и $\psi$. Обозначение $\psi \varphi$, где самое правое отображение действует первым.
\end{definition}

\subsubsection{Технологии}

\begin{prob}
	3.6.1 Матрицы ортогонального проектирования геометрического трехмерного пространства ...
\end{prob}

\section{Линейные преобразования линейных пространств}
\subsection{Линейные преобразования линейных пространств}

Вспомним, что линейным преобразованием является такое линейное отображение, которое переводит линейное пространство в себя. Поэтому теперь не нужно задавать пару базисов, достаточно будет одного.

\begin{definition}
	Матрицей линейного преобразования $\varphi : L_n \to L_n$ в базисе $e = (e_1, \ldots, e_n)$ называется матрица, столбцы которой (взятые в естественном порядке) -- координатные столбцы векторов $\varphi(e_1), \ldots, \varphi(e_n)$ в базисе $e$.
\end{definition}
	
Теперь в формуле $A' = F^{-1} A S$ остается единственная матрица перехода $S$ $\Rightarrow$ $A' = S^{-1} A S$. Кроме того линейные преобразования обладают большим количеством инвариантов.

\begin{definition}
	Подпространство $L'$ линейного пространства $L$ называется инвариантным относительно $\varphi$ (или $\varphi$-инвариантным), если $\forall x \in L'$ $\varphi(x) \in L'$.
\end{definition}

Т.е. вектора подпространства $L'$ не выводятся за его пределы преобразованием $\varphi$. Также можно сказать, что $\varphi(L')$ является линейным подпространством в $L'$.

\begin{propos}
	Пусть $\dim L = n$, $\varphi$ -- некоторое линейное преобразование, $L_k'$ -- $\varphi$-инвариантное подпространство $L$. Выберем в $L_n$ базис $e$ так, что $e_1, \ldots, e_k \in L_k'$. В таком базисе матрица $\varphi$ имеет блочный вид:
	
	\[
		A = \begin{pmatrix}
			A_1 & A_2 \\
			0 & A_3 
		\end{pmatrix}
	\]
\end{propos}

\begin{definition}
	Если изменить множество векторов, на котором определено $\varphi$, взяв вместо $L_n$ $\varphi$-инвариантное подпространство $L_k'$, тогда получившееся (линейное) преобразование $\varphi': L_k' \to L_k'$ будем называть ограничением $\varphi$ на $L_k'$.
\end{definition}

\subsubsection{Технологии}

\begin{prob}
	Доказать, что если операторы $\varphi$ и $\psi$ на $V$ коммутируют, то $\ker \psi \subset V$ $\varphi$-инвариантно (аналогично $\ker \varphi$ $\psi$-инвариантно).
\end{prob}
\begin{proof}
	Хотим показать, что для $U = \ker \psi$, верно $\forall u \in U$ $\varphi(u) \in U$, т.е. по определению ядра $\psi(\varphi(u)) = 0$. По условию $\varphi \psi = \psi \varphi$, тогда $\psi(\varphi(u)) = \varphi(\psi(u))$, где $\psi(u) = 0$ ($u$ из ядра $\psi$) $\Rightarrow$ $\varphi(0) = 0$ как линейный оператор.
\end{proof}

Интересно придумать пару примеров коммутирующих операторов: $\varphi^2$ и $\varphi$, $\varphi - \lambda id$ и $\varphi$. Особый интерес представляет пара $\varphi$ и $\varphi - \lambda id$, т.к. используется в определении собственного подпространства $V_\lambda = \ker(\varphi - \lambda id_V) \ne 0$. Оно является $\varphi$-инвариантным.

\begin{prob}[4.1.2]
	Найти подпространства трехмерного геометрического пространства, инвариантные относительно поворота на угол $\alpha$ вокруг некоторой прямой.
\end{prob}

\begin{prob}[4.1.3]
	Найти все инвариантные подпространства для оператора дифференцирования $\frac{d}{dx}$ в пространстве $V = \mathbb{R}[x]_n$.
\end{prob}
\begin{proof}
	Т.к. при дифференцировании степень многочлена убывает, для исходного пространства можно построить цепочку вложенных $\varphi$-инвариантных подпространств 
	\[
		0 \subset \mathbb{R}[x]_0 \subset \mathbb{R}[x]_1 \subset \ldots \subset \mathbb{R}[x]_n
	\]
\end{proof}

\begin{prob}
	Доказать, что если линейный оператор $\varphi$ на $n$-мерном линейном пространстве имеет собственный вектор, то для $\varphi$ существует и $(n-1)$-мерное инвариантное подпространство.
\end{prob}
\begin{proof}
	Собственным называется вектор, такой что $\varphi(v) = \lambda v$, где $\lambda$ -- собственное значение. Определим оператор $\psi = \varphi - \lambda id_V : V \to V$, имеющий ненулевое ядро $V_\lambda = \ker \psi \ne 0$. То есть образ оператора $\psi$ меньше всего пространств $V$ $\Rightarrow$ $\img \psi \subset U \subset V$, $\dim U = n-1$.
	
	Покажем, что $U$ -- $\varphi$-инвариантно. 
	\[
		\varphi(u) = \varphi(u) - \lambda u + \lambda u = (\psi(u) + \lambda u) \in U
	\]
	т.к. оба слагаемых лежат в $U$, значит $U$ -- $\varphi$-инвариантно.
\end{proof}

\begin{prob}[4.1.6]
	Доказать, что для оператора $\varphi$ в конечномерном пространстве $V$ над полем $\mathbb{C}$ существует такой базис в $V$, в котором матрица $\varphi$ является верхнетреугольной.
\end{prob}

\begin{prob}[4.1.7]
	Доказать, что для оператора $\varphi: V \to V$, $\dim V = n$ существует базис, в котором его матрица верхнетреугольная т.и т.т., когда в $V$ существует цепочка вложенных $\varphi$-инвариантных подпространств
	\[
		0 = V_0 \subset V_1 \subset V_2 \subset \ldots \subset V_n = V,
	\]
	таких что $\dim V_k = k$, $0 \le k \le n$.
\end{prob}

\subsection{Собственные векторы}

Будем рассматривать одномерное линейное подпространство $L_1$ линейного пространства $L$. Базис $L_1$ состоит из единственного вектора $x \ne 0$ $\Rightarrow$ $\forall y \in L_1$ существует число $\alpha$, т.ч. $y = \alpha x$.

Если $L_1$ инвариантно относительно некоторого линейного преобразования $\varphi: L \to L$, тогда $\varphi(x) \in L_1$ $\Rightarrow$ найдется число $\lambda$, что $\varphi(x) = \lambda x$.
	
Обратное утверждение тоже будет верным. Если $\exists x \ne 0$ из $L_1$ и выполняется условие $\varphi(x) = \lambda x$, то оно будет выполняться и для любого $y \in L_1$ (просто домножаем равенство на любое число) $\Rightarrow$ $L_1$ $\varphi$-инвариантно.

\begin{definition}
	Ненулевой вектор $x$, удовлетворяющий соотношению 
	\begin{equation}
		\varphi(x) = \lambda x, 
	\end{equation}
	называется собственным вектором преобразования $\varphi$, а число $\lambda$ -- собственным значением $\varphi$. 
\end{definition}

Будем также говорить, что собственный вектор принадлежит собственному значению. В ближайшее время нас будет интересовать задача поиска всех собственных значений (спектра) преобразования $\varphi$. 

Если в $L_n$ выбрать базис $e$, тогда операторное равенство можно переписать в координатном виде
\begin{equation} \label{self_vec_coord}
	A \xi = \lambda \xi,
\end{equation}
где $x = e \xi$, $A$ -- матрица $\varphi$ в $e$. Равенство (\ref{self_vec_coord}) можно переписать в виде 
\begin{equation}
	(A - \lambda E) \xi = 0
\end{equation}
-- это система из $n$ линейных однородных уравнений с $n$ неизвестными, нас интересуют нетривиальные решения. Матрица $(A - \lambda E)$ -- вырожденная, поэтому 
\begin{equation}
	\det (A - \lambda E) = 0
\end{equation}
Полученное уравнение будем называть характеристическим, ему должны удовлетворять все собственные значения $\varphi$. В вещественном пространстве комплексные корни уравнения (\ref{self_vec_coord}) не могут быть собственными значениями!

\begin{theorem}
	В комплексном линейном пространстве все корни характеристического уравнения и только они являются собственными значениями преобразования. В вещественном пространстве это верно только для вещественных корней.
\end{theorem}

Выражение $\det (A - \lambda E)$ -- это многочлен, степень которого равна порядку матрицы, далее будем называть его характеристическим многочленом матрицы $A$.

\begin{propos}
	Если $A = (a_{ij})$, $i,j = 1 \ldots n$ -- матрица, то характеристический многочлен имеет вид
	\[
		(-1)^n \lambda^n + (-1)^{n-1} (a_{11} + \ldots +  a_{nn}) \lambda^{n-1} + \ldots + \det A
	\]
\end{propos}

Заметим, что в вещественном пространстве характеристический многочлен четной степени может не иметь вещественных корней $\Rightarrow$ $\varphi$ не имеет собственных векторов. Пример: поворот на угол, не кратный $\pi k$, $k \in \mathbb{Z}$. В комплексном пространстве собственное значение всегда есть $\Rightarrow$ есть собственный вектор $\varphi$.

\subsubsection{Технологии}
На этом этапе полезно потренироваться находить собственные значения и собственные вектора различных линейных операторов, а также понять, что делать, когда их нет.

\section{Свойства собственных значений и собственных векторов линейных преобразований}
\subsection{Собственное подпространство}

\begin{propos}
	Все собственные векторы, принадлежащие одному собственному значению, вместе с нулевым вектором образуют в линейном пространстве $L_n$ линейное подпространство ("собственное подпространство").
\end{propos}
\begin{proof}
	Координатные столбцы собственных векторов (с учетом нулевого решения!) является фундаментальной системой решений однородной СЛАУ, которое является пространством.
\end{proof}

\begin{theorem}
	Если собственные векторы $x_1, \ldots, x_k$ принадлежат попарно различным собственным значениям $\lambda_1, \ldots, \lambda_k$, то они линейной независимы.
\end{theorem}

По сути это значит, что сумма собственных подпространств -- прямая.

\begin{propos}
	Если $A$ и $A'$ -- матрицы преобразования $\varphi$ в различных базисах, то их характеристические многочлены совпадают.
\end{propos}
\begin{proof}
	\[ 
		\det (A' - \lambda E) = \det(S^{-1} A S - \lambda E) = \det(S^{-1} A S - S^{-1} \lambda S)
	\]
	\[
	  	= \det(A - \lambda E) \det S^{-1} \det S = \det(A - \lambda E)
	\]
	 
\end{proof}

Т.о. характеристический многочлен матрицы $A$ можно называть характеристическим многочленом преобразования $\varphi$. Его коэффициенты не зависят от выбора базиса, т.е. являются инвариантами $\varphi$. А значит такие значения как $\det A$ и $\tr A$ также являются инвариантами.

Рассмотрим характеристический многочлен $P(\lambda)$. Если он представим в виде
\[
	P(\lambda) = (\lambda - \lambda_0)^s P_2(\lambda), \; s \ge 1
\]
то будем говорить, что многочлен имеет корень $\lambda_0$ кратности $s \ge 1$ (при $s = 1$ корень называется простым).

\begin{theorem}[оценка размерности собственного пространства]
	Пусть собственное значение $\lambda_0$ линейного преобразования $\varphi$ является корнем кратности $s$ характеристического уравнения $P(\lambda)$. Тогда ему принадлежит не более $s$ линейно независимых собственных векторов (меньше -- возможно, больше -- нет!).
\end{theorem}

Пример такой матрицы

\[
	A = \begin{pmatrix}
		1 & 1 \\
		0 & 1 
	\end{pmatrix}
\]
она имеет собственное значение $\lambda_0 = 1$ кратности 2 и единственный собственный вектор $x = (1 \; 0)^T$. Проблему нехватки собственных векторов можно в каком-то смысле преодолеть, если воспользоваться оператором $(\varphi - \lambda id)$ несколько раз, тогда мы перейдём к более общей формулировке корневых подпространств. Подробности этого фокуса описаны в теореме о корневом разложении, которую мы сейчас не будем рассматривать.

\subsection{Приведение матрицы преобразования к диагональному виду}
\begin{definition}
Матрица $A = (a_{ij})$, $i,j = 1,\ldots,n$ называется диагональной, если $a_{ij} = 0$ $\forall i \ne j$
\[
	A = \begin{pmatrix}
		a_{11} & 	    & 0 \\
		       & \ldots &   \\
		0      &        & a_{nn}
	\end{pmatrix}
\]
\end{definition}

На диагонали, впрочем, вполне могут тоже стоять нули.

\begin{propos}
	Матрица линейного преобразования $\varphi$ в базисе $e_1, \ldots, e_n$ диагональна $\Leftrightarrow$ все векторы базиса -- собственные векторы $\varphi$.
\end{propos}
\begin{proof}
	$\Leftarrow$ $e_i$ -- собственный вектор, тогда $\varphi(e_i) = \lambda_i e_i$, то есть $i$-й элемент координатного столбца вектора $\varphi(e_i)$ в базисе $e$ равен $\lambda_i$, а остальные значения -- нули. Но $i$-й столбец матрица преобразования $\varphi$ -- это координатный столбец $\varphi(e_i)$ в базисе $e$. Получается, что нам достаточно упорядочить столбцы базиса (и матрицы) так, чтобы значения $\lambda_i$ оказались на диагонали.
	
	$\Rightarrow$ В обратную сторону доказательство строится аналогично, только рассуждения проводятся в обратном порядке.
\end{proof}

Т.о. если преобразование $\varphi$ имеет $n$ попарно различных собственных значений, то найдется и базис из собственных векторов. То же самое можно сформулировать в матричном виде. Если все корни характеристического матрицы $A$ попарно различны, то существует невырожденная матрица $S$ (перехода от старого базиса к новому базису), такая что матрица $S^{-1} A S$ -- диагональная. При этом, если $A$ -- вещественная и мы хотим, чтобы $S$ также была вещественной, то необходимо, чтобы корни характеристического многочлена были вещественными.

Но для кратных корней может матрица может оказаться недиагонализируемой! 

\subsubsection{Технологии}

Разберем тонкости работы с базисами из собственных векторов, а также ограничения, которые возникают при попытке его построить.

\begin{prob}[5.3.1]
	Найдите собственные значения и собственные подпространства оператора дифференцирования на пространстве многочленов $\mathbb{R}[x]_n$ степени не выше $n$.
\end{prob}
\begin{soln}
	Поймём какие собственные значения может иметь такой оператор $\varphi = \frac{d}{dx}$ на $\mathbb{R}[x]_n$. Если дифференцировать многочлен достаточно долго (в нашем случае $n+1$ раз), то оператор $\varphi^{n+1}$ станет нулевым $\varphi^{n+1} = 0$ (здесь ноль записан именно в операторном смысле!).
	
	С другой стороны пусть $v \ne 0$ $\varphi(v) = \lambda v$. Продолжим последовательно применять $\varphi$, тогда
	\[
	 	\varphi^{n+1} (v) = \lambda^{n+1} v = 0, \; v \ne 0 \Rightarrow \lambda^{n+1} = 0 \Rightarrow \lambda = 0
	\]
	Получается, что единственным возможным собственным значением является $\lambda = 0$. Ядро такого преобразования будет нетривиальным (туда попадут все векторы, соответствующие нулевому собственному значению). Т.е. ядро будет собственным подпространством для нулевого собственного значения. 
	
	Для оператора дифференцирования ядром являются константы, собственное пространство одномерно: $V_0 = \langle 1 \rangle \subset \mathbb{R}[x]_n$. Т.е. для оператора дифференцирования при $n \ge 1$ базиса состоящего из собственных векторов этого оператора не существует. Собственные векторы образуют одномерное пространство, а нам этого недостаточно. Поэтому базис из собственных векторов построить нельзя. Оператор дифференцирования нельзя диагонализировать.
\end{soln}

\begin{prob}[5.3.2]
	Линейное преобразование вещественного пространства задано матрицей. Найти собственные значения и максимальную линейно независимую систему собственных векторов преобразования. если из собственных векторов можно составить базис, то записать в нём матрицу преобразования.
\end{prob}
\begin{soln}
	Возьмём такую матрицу:
	\[
	A = \begin{pmatrix}
		5 & -2 & 0 \\
		4 & -1 & 0 \\
		8 & -4 & 1
	\end{pmatrix}
	\]
	
	вычисляем характеристический многочлен $\det(A - tE) = \det(tE - A) = 0$
	\[
		A = \begin{vmatrix}
			5-t & -2 & 0 \\
			4 & -1-t & 0 \\
			8 & -4 & 1-t
		\end{vmatrix} = (1 - t)(t^2 - 4t +3)
	\]
	$\lambda_1 = t = 1$ (кратности 2), $\lambda_2 = t = 3$. Размерность подпространства, соответствующего собственному значению не превосходит его кратности. Рассмотрим сперва $\lambda_1 = 1$, подставим его вместо $t$ и получим (вырожденную) матрицу
	\[
		\begin{pmatrix}
			4 & -2 & 0 \\
			4 & -2 & 0 \\
			8 & -4 & 0
		\end{pmatrix} \sim
		\begin{pmatrix}
			2 & -1 & 0 \\
			0 & 0 & 0 \\
			0 & 0 & 0
		\end{pmatrix}
	\]
	$\rank = 1$, значит собственно подпространство, отвечающее с.з. $\lambda_1 = 1$ двумерно, как пространство решений системы $A - \lambda E = 0$, а фундаментальная система решений будет базисом. Выберем пару базисных векторов и построим подпространство $V_1 = \langle (1 \; 2 \; 0)^T, (0 \; 0 \; 1)^T \rangle$. 
	
	Для собственного значения $\lambda_2 = 3$ собственное подпространство имеет вид $V_3 = \langle (1 \; 1 \; 2)^T \rangle$. Т.о. найден базис из собственных векторов. Матрица $A$ в этом базисе будет иметь вид
	\[
		A' = \begin{pmatrix}
			1 & 0 & 0 \\
			0 & 1 & 0 \\
			0 & 0 & 3
		\end{pmatrix} \quad		
		S = \begin{pmatrix}
			1 & 0 & 1 \\
			2 & 0 & 1 \\
			0 & 1 & 2
		\end{pmatrix} \quad		
		S^{-1} = \begin{pmatrix}
			-1 & 1 & 0 \\
			-4 & 2 & 1 \\
			2 & -1 & 0
		\end{pmatrix}		
	\]
	Размещение собственных значений на диагонали соответствует размещению столбцов собственных векторов матрицы перехода $S$. Аккуратно выполнив умножение, можно проверить, что $A' = S^{-1} A S$. 
	
	Теперь возьмём другую матрицу:
	\[
		A = \begin{pmatrix}
			4 & -5 & 2 \\
			5 & -7 & 3 \\
			6 & -9 & 4
		\end{pmatrix}
	\]
	$\lambda_1 = 0$ (кратности 2) $V_1 = \langle (1 \; 2 \; 3)^T \rangle$, $\lambda_2 = 1$ $V_1 = \langle (1 \; 1 \; 1)^T \rangle$. Базис из собственных векторов построить нельзя, матрица недиагонализируема.
\end{soln}

\begin{propos}
	Пусть матрица 
	\[
		A = \begin{pmatrix}
			a_{11} & a_{12} \\
			a_{21} & a_{22} 
		\end{pmatrix}
	\]
	имеет кратное собственное значение и не диагонально, то $A$ -- недиагонализируема.
\end{propos}

\begin{prob}
	\begin{enumerate}
		\item Найти собственные значения и собственные векторы оператора $\varphi$, заданного в некотором базисе матрицей 
		\[
			A = (a_1, \ldots, a_n)^T (b_1, \ldots, b_n) \ne 0
		\]
		\item Найдите критерий диагонализируемости преобразования $\varphi$.
	\end{enumerate}
\end{prob}

\section{Евклидово пространство}

Как ни странно, евклидово пространство является для нас наиболее знакомым и привычном объектом из всего что встречалось ранее. Здесь, наконец-то, мы получаем возможность измерять расстояния и углы с помощью удачно определенного скалярного произведения. 

\subsection{Определение евклидова пространства}
\begin{definition}
	Вещественное линейное пространство $L_n$ называем евклидовым $E_n$, если 
	\[
		\forall x,y \in L_n \to (x,y) \in \mathbb{R}: \; \forall x,y,z \in L_n \; \forall \alpha \in \mathbb{R}
	\]	
	выполняются аксиомы
	\begin{enumerate}
		\item $(x,y) = (y,x)$
		\item $(x+y, z) = (x,z) + (y,z)$
		\item $(\alpha x, y ) = \alpha(x,y)$
		\item $(x, x) > 0$, если $x \ne 0$
	\end{enumerate}
\end{definition}

\begin{definition}
	Число $(x,y)$, удовлетворяющее аксиомам 1-4, называем скалярным произведением векторов $x$ и $y$.
\end{definition}

\begin{propos}
	$\forall x,y \in E_n$, $\forall \alpha \in \mathbb{R}$ $(x, \alpha y) = \alpha (x,y)$
\end{propos}

\begin{propos}
	$\forall x,y \in E_n$, $\forall \alpha \in \mathbb{R}$ $(x, y + z) =  (x,y) + (x,z)$
\end{propos}

Имея в руках скалярное произведение, мы можем определять более привычно звучащие понятия, такие как длина и угол.

\begin{definition}
	Длиной вектора $x \in E_n$ будем называть величину $|x|$, равную корню из скалярного произведения вектора с самим собой $|x| = \sqrt{(x,x)}$.
\end{definition}

\begin{definition}
	Углом между векторами $x, y \in E_n$, $x \ne 0$, $y \ne 0$ назовём величину $\varphi \in [0, 
	\pi]$ :
	\[
		\cos \varphi = \dfrac{(x,y)}{|x| \cdot |y|}
	\]
\end{definition}

Здесь необходимо убедиться в корректности определения, проверив, что $|\cos \varphi| \le 1$. Рассмотрим неравенство, которое позволит это сделать. 

\begin{propos}[неравенство Коши-Буняковского-Шварца]
	$\forall x,y \in E_n$, $(x,y)^2 \le (x,x) (y,y)$.
\end{propos}
\begin{proof}
	$\forall x,y \in En$, $\forall \alpha, \beta \in \mathbb{R}$
	\[
		(\alpha x + \beta y, \alpha x + \beta y) = \alpha^2  (x,x) + 2 \alpha \beta + \beta^2 (y,y) \ge 0
	\]
	Т.е. условие неотрицательности выполняется для любых значений $\alpha, \beta$, для конкретных значения $\alpha = (y,y)$, $\beta=(-x,y)$ оно тоже выполнится
	\[
		(y,y)[(x,x)(y,y) - (x,y)^2] \ge 0
	\]
	Т.о. неравенство доказано. 	
\end{proof}

Для нулевого вектора удобно угол не определять, хотя некоторые интересные свойства он всё равно сохранит.

\subsubsection{Технологии}

Самое время понять, что евклидово пространство может принимать и более необычные формы, но ключевым элементом всегда является скалярное произведение.

\begin{prob}[6.2.1.]
	Задача. Неравенство Коши-Буняковского
\end{prob}

\subsection{Ортогональные системы векторов}

\begin{definition}
	Два ненулевых вектора называются ортогональными, если угол между ними равен $\frac{\pi}{2}$.
\end{definition}

Также для удобства будем считать, что нулевой вектор ортогонален любому другому.

\begin{propos}
	Только нулевой вектор ортогонален каждому вектору.
\end{propos}

\begin{definition}
	Система $f_1, f_2, \ldots, f_k$ ненулевых векторов $E_n$ называется ортогональной, если $(f_i, f_j) = 0$ при $i \ne j$. Если также $\forall i = 1, \ldots, k$ $(f_i, f_i) = 1$, то система называется ортонормированной.
\end{definition}

\begin{propos}
	Ортогональная система линейно независима.
\end{propos}

Разберем теперь задачу построения ортогональной системы на основе некоторой заданной линейно независимой системы векторов.

\begin{prob}
	$f$ -- произвольная линейно независимая система в $E_n$, необходимо построить из нее ортогональную систему $g$.
\end{prob}
\begin{soln}
	Будем использовать алгоритм ортогонализации Грама-Шмидта
	
	\begin{enumerate}
		\item $g_1 = f_1$ в качестве первого вектора ортогональной системы берем первый вектор системы $f$.
		\item $g_2 = f_2 - \alpha_1 g_1$, где $\alpha$ находится из условия $(g_2, g_1) = (f_2, g_1) - \alpha (g_1, g_1) = 0$, т.е. скалярно умножаем обе части равенства и используем определение ортогональности: $\alpha = \frac{(f_2, g_1)}{(g_1, g_1)}$.
		\item $g_3 = f_3 - \beta_1 g_1 - \beta_2 g_2$, коэффициенты $\beta_1$, $\beta_2$ находятся аналогично из условий нулевого скалярного произведения $(g_3, g_2) = 0$ и $(g_3, g_1) = 0$.
		\item Продолжаем процесс до исчерпания векторов системы $f$.		
	\end{enumerate}
	
	При необходимости векторы можно нормировать.
\end{soln}

\begin{theorem}
	В евклидовом пространстве $E_n$ существует ортонормированный базис из $n$ векторов.
\end{theorem}
\begin{proof}
	Т.к. $E_n$ линейно и $\dim E_n = n$, то в нём найдется какой-то базис из $n$ векторов. Если провести его ортогонализацию и нормирование, то получим искомый базис.
\end{proof}

\subsubsection{Технологии}

\begin{prob}[6.3.1]
	Найти ортогональную проекцию  и ортогональную составляющую вектора $x = (2, -5, 4, -3)$ при проецировании на подпространство $U = \langle (1,2,1,0), (2,1,4,-5) \rangle$
\end{prob}
\begin{soln}
	Подпространство имеет вид $U = \langle (1,2,1,0)^T, (2,1,4,-5)^T \rangle$, но базис неортогонален, ортогонализуем его 
	\[f_1 = e_1 = (1,2,1,0)^T \]
	\[
		f_2 = e_2 - \pr_{f_1} e_2 = e_2 - \dfrac{(e_2, f_1)}{|f_1|^2} f_1 = \frac{1}{3} (2, -5, 8, -15)^T
	\]
	\[
		\pr_U x = \dfrac{(x, f_1)}{|f_1|^2}f_1 + \dfrac{(x, f_2)}{|f_2|^2}f_2 = (0,-3,2,-5)^T
	\]
	\[
		\ort_U x = x - \pr_U x = (2, -1, 2, 2)^T
	\]
\end{soln}


\begin{prob}
	Задача 6.3.2. Алгоритм Грама-Шмидта
\end{prob}

\subsection{Скалярное произведение. Матрица Грама}

Пусть $e$ -- некоторый базис в $E_n$, также есть два вектора $x = e\xi$, $y = e\eta$. Попробуем найти их скалярное произведение в координатной форме, пользуясь свойством линейности
\[
	(x,y) = \left( \sum_{i} \xi_i e_i, \sum_{j} \eta_j e_j  \right) = \sum_{i,j} \xi_i \eta_j (e_i, e_j)
\]

Можно избавиться от знаков суммирования, переписав выражение в матричном виде
\[
	(x,y) = \xi^T \Gamma \eta
\]
где матрица $\Gamma$ содержит всевозможные попарные скалярные произведения векторов базиса
\[
	\Gamma = \begin{pmatrix}
		(e_1, e_1) & (e_1, e_2) & \ldots & (e_1, e_n) \\
		(e_2, e_1) & (e_2, e_2) & \ldots & (e_2, e_n) \\
		\ldots     &     \ldots & \ldots & \ldots     \\
		(e_n, e_1) & (e_n, e_2) & \ldots & (e_n, e_n)
	\end{pmatrix}
\]
она называется матрицей Грама. Рассмотрим её свойства.

\begin{enumerate}
	\item $\Gamma^T = \Gamma$ -- матрица симметрическая, т.к. скалярное произведение коммутативно.
	\item В ортонормированном базисе $\Gamma = E$, т.к. все векторы ортогональны $(e_i, e_j) = 0$ для $i \ne j$ и имеют единичную длину.
	\item Пусть $e' = eS$, $\Gamma$, $\Gamma'$ --  матрицы Грама в базисах $e$ и $e'$, тогда $\Gamma' = S^T \Gamma S$. 
	\item В любом базисе $\det \Gamma > 0$.
\end{enumerate}

\begin{definition}
	Квадратная матрица $S$ называется ортогональной, если $S^T S = E$.
\end{definition}

Свойства ортогональных матриц
\begin{enumerate}
	\item $\det \ne 0$
	\item $S^T = S^{-1}$
	\item $S^T$ -- тоже ортогональная
	\item $|\det S| = 1$
	\item $e, f$ -- ортонормированные базис в $E_n$ и $f = eS$ $\Rightarrow$ $S$ -- ортогональная
\end{enumerate}

\subsection{Ортогональное дополнение подпространства}

\begin{definition}
	Пусть $E_k$ -- линейное подпространство $E_n$. Ортогональным дополнением $E_k$ называется множество всех $x \in E_n$, ортогональных каждому вектору из $E_k$. Обозначение: $E_k^{\perp}$.
\end{definition}

\begin{theorem}
	$E_k^{\perp}$ -- линейное подпространство $E_n$, $\dim E_k^{\perp} = n - k$.
\end{theorem}
\begin{proof}
	Шаг 1. Пусть $a_1, \ldots, a_k$ -- базис в $E_k$, тогда вектор $x$ лежит в $E_k^{\perp}$, когда все его скалярные произведения на вектора базиса равны нулю:
	\[
		x \in E_k^{\perp} \Leftrightarrow 
		\left\{
			\begin{aligned}
				(x, a_1) &= 0\\
				\ldots  \\				
				(x, a_k) &= 0
			\end{aligned} 
		\right. \quad (*)
	\]
	
	$\Rightarrow$ Если $x \in E_k^{\perp}$, система $(*)$ выполнена.	
	
	$\Leftarrow$ Уравнения системы $(*)$ выполнены, покажем, что $x$ лежит в $E_k^{\perp}$. Рассмотрим вектор $a \in E_k$, вычислим скалярное произведение $(x,a)$
	\[
		(x, a) = \left(x, \sum_{p=1}^{k}\alpha_p a_p \right) = \sum_{p=1}^{k} \alpha_p (x, a_p) = 0
	\]
	
	Шаг 2. Выберем в $E_n$ ортонормированный базис $e = (e_1, \ldots, e_n)$ и разложим по нему все векторы $a_i$ (базисные в $E_k$), получим $k$ столбцов. Транспонируем их и запишем матрицу $A \in M_{k \times n}$. Если $x = e \xi$, то 
	\[
		\left\{
			\begin{aligned}
				(x, a_1) &= 0\\
				\ldots  \\				
				(x, a_k) &= 0
			\end{aligned} 
		\right. \; \Leftrightarrow \; A\xi = 0
	\]
	$\rank A = k$, т.к. $a_1, \ldots, a_k$ -- линейно независимы, а множество решений такой СЛАУ задает $E_k^{\perp}$ в виде линейного подпространства размерности $(n-k)$.
\end{proof}

Свойства $E_k^{\perp}$

\begin{enumerate}
	\item $(E_k^{\perp})^{\perp} = E_k$ -- если взять ортогональное дополнение $E_k$ и построить к нему ортогональное дополнение ещё раз, то получится исходное подпространство.
	\item $E_n = E_k \oplus E_k^{\perp}$
	\item $\forall x \in E_n$ имеется однозначное разложение $x = x_1 + x_2$, $x_1 \in E_k$, $x_2 \in E_k^{\perp}$.
\end{enumerate}

\begin{definition}
	Будем называть $x_1$ из свойства 3 ортогональной проекцией $x$ на $E_k$, $x_2$ -- ортогональная составляющей вектора $x$, а $|x_2|$ -- расстоянием от $x$ до $E_k$.
\end{definition}

\subsubsection{Технологии}

\section{Линейные преобразования в евклидовом пространстве}
\subsection{Сопряженные линейные преобразования евклидова пространства}
Продолжаем изучать евклидово пространство $E_n$.

\begin{definition}
	Линейное преобразование $\varphi^*$ пространства $E_n$ называется сопряженным данному линейному преобразованию $\varphi$, если $\forall x, y \in E_n$
	\[
		(\varphi(x), y) = (x, \varphi^*(y)) \quad (*)
	\]
\end{definition}

\begin{propos}
	Если для $\varphi$ существует сопряженное преобразование $\varphi^*$, которые в базисе $e$ (с матрицей Грама $\Gamma$) имеют матрицы $A$, $A^*$, то 
	\[
		A^T \Gamma = \Gamma A^* \quad (**)
	\]
\end{propos}
\begin{proof}
	Пусть $x = e\xi$, $y = e\eta$, тогда из $(\varphi(x),y) = (x, \varphi^*(y))$ следует 
	\[
		(A\xi)^T \Gamma \eta = \xi^T \Gamma (A^* \eta) \Leftrightarrow \xi^T (A^T \Gamma - \Gamma A^*) \eta = 0
	\]
	Т.к. столбцы $\xi$ и $\eta$ произвольны (в частности можно брать столбцы единичной матрицы), то $A^T \Gamma - \Gamma A^* = 0$, получили искомое равенство.
\end{proof}

В ортонормированном базисе $A^* = A^T$.

\begin{theorem}
	Любое линейное преобразование $\varphi$ в $E_n$ имеет сопряженное $\varphi^*$, причем единственное.
\end{theorem}

\subsubsection{Технологии}
\begin{prob}[7.1.1]
	Матрица сопряженного преобразования
\end{prob}

\subsection{Самосопряженные преобразования}

\begin{definition}
	Линейное преобразование $\varphi$ в $E_n$ называется самосопряженным, если $\varphi = \varphi^*$. Т.е. $\forall x, y \in E_n$ $(\varphi(x), y) = (x, \varphi(y))$.
\end{definition}

Тогда для $\varphi = \varphi^*$ в любом ортонормированном базисе $e$ $A = A^T$ -- матрица преобразования будет симметрической (обратное тоже верно).

\begin{theorem}
	Все собственные значения самосопряженного преобразования вещественные.
\end{theorem}
\begin{proof}
	Пусть $A$ -- матрица самосопряженного преобразования $\varphi$ в некотором ОНБ. Предположим, что уравнение $\det(A - \lambda E) = 0$ имеет комплексный корень $\lambda_0$. Считая, что $\dim E = n$, рассмотрим СЛАУ $(A - \lambda_0 E) \xi = 0$. У системы есть нетривиальное решение $\xi_0$, подставим его и умножим обе части на строку $\bar{\xi}_0^T$ (транспонированный и комплексно сопряженный вектор $\xi_0$) слева. Тогда 
	\[
		\bar{\xi}_0^T A \xi_0 = \lambda_0 \bar{\xi}_0^T \xi_0
	\] 
	Обозначим $\alpha = \bar{\xi}_0^T \xi_0 \in \mathbb{R}$. Покажем, что $\omega =\bar{\xi}_0^T A \xi_0 $ тоже лежит в $\mathbb{R}$. Как число $\omega = \omega^T$, для произведения операция транспонирования имеет вид 
	\[
		(\bar{\xi}_0^T A \xi_0)^T = \xi_0^T A^T \bar{\xi}_0
	\]
	С другой стороны $\bar{\omega} = \xi_0^T \bar{A} \bar{\xi}_0$. Т.к. $A = \bar{A} = A^T$ $\Rightarrow$ $\bar{\omega} = \xi_0^T A \bar{\xi}_0 = \omega$ $\Rightarrow$ $\omega \in \mathbb{R}$. Итак, $\omega = \lambda_0 \alpha$, где $\omega \in \mathbb{R}$, $0 \ne \alpha \in \mathbb{R}$ $\Rightarrow$ $\lambda_0 \in \mathbb{R}$. Получили противоречие.
\end{proof}

\begin{theorem}
	Собственные векторы самосопряженного преобразования, принадлежащие попарно различным собственным значениям, ортогональны.
\end{theorem}

\begin{propos}
	Если подпространство $\tilde{E}$ инвариантно относительно самосопряженного преобразования $\varphi$, то $\tilde{E}^{\perp}$ тоже инвариантно относительно $\varphi$.
\end{propos}

\subsubsection{Технологии}

\subsection{Основная теорема о самосопряженных преобразованиях}
\begin{theorem}
	Пусть $\varphi = \varphi^*$ в $E_n$. Тогда в $E_n$ существует ОНБ из собственных векторов $\varphi$.
\end{theorem}
\begin{proof}
	Доказательство индукцией по размерности пространства.
\end{proof}

\subsection{Ортогональные преобразования}

\section{Функции на линейных пространствах}
\subsection{Линейные функции на линейном пространстве}

\begin{definition}
	Если на линейном пространстве $L$ задано правило, по которому вектору $x \in L$ ставится в соответствие число из $\mathbb{R}$ (или $\mathbb{C}$), то говорят, что на $L$  задана функция $f$. Значение $f$ на $x$ обозначим $f(x)$.
\end{definition}

Для пар векторов $x,y \in L$ будем пользоваться также обозначением $b(x,y)$. Также в дальнейший рассуждениях будем считать, что $\dim L < \infty$.

\begin{definition}
	Функция $f$ на $L_n$ называется линейной, если $\forall x,y \in L$, $\forall \alpha$
	\begin{enumerate}
		\item $f(x+y) = f(x) + f(y)$
		\item $f(\alpha x) =\alpha f(x)$
	\end{enumerate}
\end{definition}

Применим координатный способ к анализу линейных функций. Выберем базис $e = (e_1, \ldots, e_n)$ в $L_n$. Тогда $\forall x \in L_n$
\[
	x = \xi_1 e_1 + \ldots + \xi_n e_n \; \Rightarrow \; f(x) =  f(e_1) \xi_1 + \ldots +  f(e_n) \xi_n = \kappa \xi
\]
где $\kappa = (f(e_1), \ldots, f(e_n))$, $\xi = (\xi_1, \ldots, \xi_n)^T$.

\begin{definition}
	Строка $\kappa = (f(e_1), \ldots, f(e_n))$ называется координатной строкой линейной функции $f$ в базисе $e$.
\end{definition}

Координатная строка неспроста называется именно так. Пространство, в котором она задает координаты, называется сопряженным к $V$ и определяется следующим образом:

\begin{definition}
	Пусть $V$ -- векторное пространство над полем $\mathbb{R}$ ($\mathbb{C}$). Сопряженным к нему называется пространство линейных функций $V^* = L(V, \mathbb{R})$ (или $\mathbb{C}$, соответственно).
\end{definition}


\begin{definition}
	 Пусть $e = (e_1, \ldots, e_n)$ -- базис пространства $V$, $x \in V$ произвольный вектор. Определим функцию $f_i(x) = \xi_i$, где $\xi = (\xi_1, \ldots, \xi_n)^T$ -- координатный столбец вектора $x$ в базисе $e$. $f_i$ является линейным функционалом на $V$, который будем называть i-й координатной функцией в базисе $e$. Заметим также, что $f_i(e_j) = \delta_{ij}$.
\end{definition}

Используя координатные функции, можно по-другому записать выражение для функции $f$. Если $e = (e_1, \ldots, e_n)$ -- базис $V$, $\{f_i\}$ -- набор координатных функций в базисе $e$, тогда 
\[
	f = \sum_{i=1}^{n}  f(e_i) f_i
\]

Причем из координатных функций можно собрать биортогональный базис $f=(f_1, \ldots, f_n)$ для $V^*$, где $f_i(e_j) = \delta_{ij}$.


\begin{propos}[Изменение координатной строки линейной функции при замене базиса] 
    Пусть $e' = eS$, $x = e \xi = e' \xi'$, $f(x) = \kappa \xi = \kappa' \xi'$. Тогда $\kappa' = \kappa S$. 
\end{propos}
\begin{proof}
	\[
		\kappa' \xi' = \kappa \xi = \kappa (S \xi') = (\kappa S) \xi' \; \Rightarrow \; \kappa' = \kappa S
	\]
	Справедливость перехода обосновывается тем, что столбец $\xi'$ произволен, и мы можем вывести поэлементные равенства, беря последовательные столбцы единичной матрицы.
\end{proof}

Внимательно присмотревшись к доказательству, можно догадаться, что линейная функция является уже привычным линейным отображением $L_n$ в одномерное арифметическое пространство (пространство столбцов высоты 1). Поэтому доказанная формула -- частный случай формулы изменения матрицы линейного отображения при замене базисов с учетом того, что в одномерном арифметическом пространстве базис не меняется.


\subsubsection{Технологии}

Несмотря на то, что линейные функции -- это знакомый объект, стоит освоиться с новой терминологией, чтобы чувствовать себя комфортно при погружении в более сложные темы. 

\begin{prob}[координатная строка линейной функции в заданном базисе]
	Сопоставить каждому многочлену $p(x) \in \mathbb{R}[x]_n$ его значение $x = \alpha \in \mathbb{R}$. Доказать, что таким образом определена линейная функция на $V = \mathbb{R}[x]_n$. Вычислить ее координатную строку в базисе $\{1, x, x^2, \ldots, x^n\}$ в пространстве $V$.
\end{prob}
\begin{soln}
	Основная хитрость задачи в том, чтобы правильно понять, что именно является рабочим  объектом. Линейная функция, которую мы изучаем, действует в пространстве многочленов степени не выше $n$, обозначение: $V = \mathbb{R}[x]_n$. Искомое отображение сопоставляет многочлену его значение в некоторой точке
	\[
		f(\alpha)(p): p(x) \in \mathbb{R}[x]_n \to p(\alpha) \in \mathbb{R}
	\]
	Проверим, что $f$ -- линейная функция на $V$
	\begin{enumerate}
		\item $f(\alpha)(p_1 + p_2) = f(\alpha)(p_1) + f(\alpha)(p_2)$ 
		\item $f(\alpha)(\lambda p) = \lambda f(\alpha)(p)$
	\end{enumerate}
	Далее возьмём стандартный базис $\{1, x, x^2, \ldots, x^n\}$ и рассмотрим значение функции 
	\[
		f(\alpha)(x^k) = \alpha^k
	\]
	Значит координатная строка примет вид $\{1, \alpha, \alpha^2, \ldots, \alpha^n\}$
\end{soln}



\begin{prob}
	Пусть $C$ -- матрица перехода между базисами $\{e_1, \ldots, e_n\}$ и $\{e_1', \ldots, e_n'\}$ пространства $V$. Найти матрицу перехода между соответствующими биортогональными базисами $\{\varepsilon_1, \ldots, \varepsilon_n\}$ и $\{\varepsilon_1', \ldots, \varepsilon_n'\}$ в $V^*$.
\end{prob}
\begin{soln}
	Базисы $\{\varepsilon_1, \ldots, \varepsilon_n\}$ и $\{\varepsilon_1', \ldots, \varepsilon_n'\}$ заданы в сопряженном пространстве $V^*$ и представляют собой координатные функции (т.е. функция возвращает координату вектора: $\varepsilon_i(v) = v_i$). 
	
	Известно, что $e' = eC$ в пространстве $V$, т.е. для любого вектора $v \in V$ 
	\[
		v = C v'
	\]
	Что равносильно равенству для координатных функций
	\[
		\begin{pmatrix}
		 	\varepsilon_1(v) \\		 	
		 	\vdots \\
			\varepsilon_n(v)  
		\end{pmatrix} = C 
		\begin{pmatrix}
			\varepsilon_1'(v') \\		 	
			\vdots \\
			\varepsilon_n'(v')  
		\end{pmatrix}
 	\]
	\[
		(\varepsilon_1 , \ldots, \varepsilon_n) = (\varepsilon_1' , \ldots, \varepsilon_n') C^T
	\]
	
\end{soln}

\colorbox{yellow}{TO-DO: добавить практически считаемый пример}

\begin{prob}
	Пусть базису $\{e_1, e_2, e_3\}$ пространства $V$ биортогонален базис $\{\varepsilon_1, \varepsilon_2, \varepsilon_3\}$ пространства $V^*$. Найти базис в $V^*$, биортогональный базису $e_1' = e_1 + e_2$, $e_2' = e_2 + e_3$, $e_3' = e_3$.
\end{prob}
\begin{soln}
	
\end{soln}



\subsection{Билинейные функции (формы) на линейном пространстве}

\begin{definition}
	Функция $b$ на $L_n$ называется билинейной, если она линейна по каждому аргументу $\forall x, y, z \in L_n$, $\forall \alpha$	
	\begin{enumerate}
		\item $b(x+y, z) = b(x,z) + b(y,z)$
		\item $b(\alpha x, y) =\alpha b(x, y)$
		\item $b(x,y+ z) = b(x,y) + b(x,z)$
		\item $b(x, \alpha y) =\alpha b(x, y)$
	\end{enumerate}
\end{definition}

Также для описания таких функций будем использовать термин билинейная форма (БФ). Некоторые авторы различают эти термины, считая, что без базиса может быть задана функция, которая представляется в базисе билинейной формой, но мы не будем.

Пусть $e$ -- базис в $L_n$, $x = e\xi$, $y = e\eta$, тогда 
\[
	b(x,y) = b\left( \sum_{i} \xi_i e_i, \sum_{j} \eta_j e_j \right) = \sum_{i,j} \xi_i \eta_j b(e_i, e_j) = \sum_{i,j} \xi_i \beta_{ij} \eta_j  = \xi^T B \eta
\]
где $B = (\beta_{ij}) \; i,j = 1,\ldots, n$ -- матрица БФ в базисе $e$. 

Рассмотрим, что происходит с БФ при смене базиса $e' = eS$
\[
	b(e_i', e_j') = b\left( \sum_{k} S_{ik} e_i, \sum_{m} S_{jm} e_j \right) =  \sum_{k, m} S_{ik} S_{jm} b(e_k, e_m) = \sum_{k, m} S_{ik} \beta_{km} S_{jm} \; \Rightarrow \; B' = S^T B S
\]

\begin{definition}
	Пусть $\forall x,y \in L_n$ $b(x,y) = b(y,x)$, тогда БФ $b$ называется симметричной.
\end{definition}

\begin{propos}
	БФ симметрична $\Leftrightarrow$ ее матрица симметрическая в любом базисе.
\end{propos}



\subsection{Квадратичные функции (формы) на линейном пространстве}

\begin{definition}
	Пусть $b$ -- симметричная БФ на $L_n$. Квадратичной формой (КФ) назовём функцию $k$, такую что $\forall x \in L_n$ 
	\[
		k(x) = b(x,x)
	\]
\end{definition}

\begin{propos}
	Пусть $k$ -- квадратичная форма на $L_n$. Тогда существует единственная симметричная БФ $b$, порождающая $k$.
\end{propos}

\begin{definition}
	Матрицей квадратичной формы называется матрица порождающей её симметричной билинейной формы (в том же базисе).
\end{definition}

Используя свойства билинейной формы, можно записать частные формулы для квадратичной формы
\[
	k(x) = \xi^T B \xi
\]
а при замене базиса $B' = S^T B S$. Если расписать выражение для квадратичной формы, то можно обнаружить подобные члены $i \ne j$ $\beta_{ij} \xi_i \xi_j = \beta_{ji} \xi_j \xi_i$, которые можно привести
\[
	k(x) = \beta_{11} \xi_1^2 + 2 \beta_{12} \xi_1 \xi_2 + \beta_{22} \xi_2^2 + 2\beta_{13} \xi_1 \xi_3 + \ldots
\]

\begin{definition}
	Если в некотором базисе КФ $k$ имеет вид 
	\[
		k(x) = \sum_{i} \varepsilon_i \xi_i^2
	\]
	то такой вид назовём диагональным. Если дополнительно потребовать, чтобы все $\varepsilon_i \in \{-1, 0, 1\}$, то вид будет каноническим.
\end{definition}

\begin{theorem}
	Для любой КФ $k$ на $L_n$ найдется базис, в котором она будет иметь диагональный вид.
\end{theorem}
\begin{proof}
	Первый шаг.
	
	а) Неособый случай, $\beta_{11} \ne 0$. Будем поочередно выполнять преобразования строк и столбцов матрицы КФ.  Первую строку $B$, умноженную на $\frac{\beta_{1i}}{\beta_{11}}$, из второй. Затем выполним аналогичное преобразование для столбца. Пройдя по всем строкам и столбцам получим матрицу
	\[
		B_1 = \begin{pmatrix}
			\varepsilon_1 & 0 & \cdots & 0 \\
			0 &  &  &  \\
			\vdots &  & C_1  &  \\
			0 &  &  &  
		\end{pmatrix} \quad (*)
	\]
	$C_1 \in M_{(n-1) \times (n-1)}$ и $C_1 = C_1^T$.
	
	б) Особый случай $\beta_{11} = 0$. Если первая строка и первые столбец нулевые, то всё уже хорошо. Если нет, и на $i$-м месте находится ненулевой элемент, то просто добавим $i$-строку к первой и $i$-й столбец к первому. Получили неособый случай.
	
	После $k$ шагов получим матрицу
	\[
		B_k = \begin{pmatrix}
			\varepsilon_1 &    &  & & \\
			  & \cdots &   &   &  0 &     \\
			 & & \varepsilon_k  & & & \\
			 & & & & & \\
 			 &0 & & & C_k & \\
 			 & & & & & \\
		\end{pmatrix}
	\]
	После $(n-1)$ шага всё закончится. Пусть $S = S_1 S_2 \ldots S_n$ -- произведение всех матрицы элементарных преобразований, тогда $B' = S^T B S$ в базисе $e' = eS$ диагональная.
\end{proof}

Элементарные преобразования могут быть и какими-то другими. Важно лишь, чтобы сохранялась симметричность матрицы (т.е. за преобразованием строки следовало преобразование столбца). После приведения матрицы к диагональному виду вполне реально разобраться, как получить канонический вид. Для этого достаточно нормировать каждый вектор, соответствующий $ \varepsilon_i \ne 0$.

\subsubsection{Технологии}

\begin{prob}
	Составить матрицу билинейной функции 
	\[
		b(x,y) = 2 x_1 y_1 - x_1 y_2 - x_2 y_1 - 5 x_2 y_2
	\]
	 в двумерном пространстве и записать соответствующую ей квадратичную функцию.
\end{prob}
\begin{soln}
	\[
		b(x,y) = \sum_{i,j}b_{ij}x_i y_j
	\]
	Чтобы записать матрицу билинейной формы, нужно пристально посмотреть функцию
	\[
		B = \begin{pmatrix}
			2 & -1 \\
			-1 & -5 
		\end{pmatrix}
	\]
	В матричной форме билинейная функция выглядит вот так:
	\[
		b(x,y) = \begin{pmatrix}
			x_1 & x_2 			
		\end{pmatrix} 
		\begin{pmatrix}
			2 & -1 \\
			-1 & -5 
		\end{pmatrix}
		\begin{pmatrix}
			y_1 \\
			y_2 			
		\end{pmatrix} 
	\]
\end{soln}



\section{Ранг и индекс квадратичной формы на линейном пространстве}
\subsection{Ранг и индекс квадратичной формы}

\begin{propos}
	Пусть $\det A \ne 0$ и определены произведения $AB$ и $CA$, тогда $\rank AB = \rank B$, $\rank CA = \rank C$.
\end{propos}
\begin{proof}
	Следует из того, что ранг произведения матриц не превосходит ранга сомножителей.
\end{proof}

\begin{theorem}
	Пусть $B$ -- матрица КФ в базисе $e$. Тогда $\rank B$ не зависит от выбора базиса (является инвариантом).
\end{theorem}
\begin{proof}
	Если $e' = eS$, а $B'$ -- матрица КФ в базисе $e'$, то $B' = S^T B S$, причем  $\det S \ne 0$. Получается, что $\rank B' = \rank B S = \rank B$.
\end{proof}

Т.к. ранг матрицы КФ является инвариантом, число ненулевых коэффициентов КФ в каноническом виде не зависит от базиса.

\begin{definition}
	Число не равных нулю коэффициентов $\varepsilon_i$ в каноническом виде квадратичной формы $k$ называется рангом $k$.
\end{definition}

Выше мы показали, что $\rank(k)$ не зависит от базиса и равен рангу матрицы КФ в данном (любом) базисе $B$. 

\begin{definition}
	Запись $k > 0$ на $L_n$ будем читать как КФ положительно определена на $L_n$ , если $\forall x \ne 0$ $x \in L_n$  $k(x) > 0$.
\end{definition}

\begin{definition}
	$k < 0$ на $L_n$ -- КФ отрицательно определена на $L_n$, если $\forall x \ne 0$ $x \in L_n$  $k(x) < 0$.
\end{definition}

\begin{definition}
	$k \ge 0$ на $L_n$ -- КФ положительно полуопределена на $L_n$, если $\forall x$ $x \in L_n$  $k(x) \ge 0$.
\end{definition}

\begin{definition}
	$k \le 0$ на $L_n$ -- КФ отрицательно полуопределена на $L_n$, если $\forall x$ $x \in L_n$  $k(x) \le 0$.
\end{definition}

Будем считать также, что на нулевом линейном пространстве всякая КФ одновременно положительно и отрицательно определена. Тогда в $L_n$ существует подпространство, на котором  $k < 0$, а если их несколько, то можно выбрать подпространство наибольшей размерности.

\begin{definition}
	$L^{(-)}$ -- подпространство в $L_n$ максимальной размерности из всех подпространств, на которых $k < 0$. $\dim L^{(-)}$ называется индексом КФ $k$. Обозначение: $\ind{k}$.
\end{definition}

\subsection{Закон инерции квадратичных форм}

\begin{theorem}[Закон инерции квадратичных форм]
	Число отрицательных и число положительных коэффициентов КФ в каноническом виде не зависит от базиса, в котором она была приведена к каноническому виду. Другими словами, если в каком-то базисе КФ приведена к каноническому виду, то число отрицательных коэффициентов равно индексу КФ.
\end{theorem}

\subsection{Критерий Сильвестра}

\begin{theorem}
	КФ $k > 0$ положительно определена на $L_n$ $\Leftrightarrow$ $\forall K = 1,\ldots,n: M_k > 0$, где $M_K$ -- главные миноры матрицы $B = (\beta_{ij})$ КФ $k$.
\end{theorem}

\section{Билинейные квадратичные формы в евклидовых пространствах}


\end{document} % конец документа
 